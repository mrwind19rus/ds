{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1594            6.2             0.600         0.08             2.0      0.090   \n1595            5.9             0.550         0.10             2.2      0.062   \n1596            6.3             0.510         0.13             2.3      0.076   \n1597            5.9             0.645         0.12             2.0      0.075   \n1598            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1594                 32.0                  44.0  0.99490  3.45       0.58   \n1595                 39.0                  51.0  0.99512  3.52       0.76   \n1596                 29.0                  40.0  0.99574  3.42       0.75   \n1597                 32.0                  44.0  0.99547  3.57       0.71   \n1598                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  \n0         9.4        5  \n1         9.8        5  \n2         9.8        5  \n3         9.8        6  \n4         9.4        5  \n...       ...      ...  \n1594     10.5        5  \n1595     11.2        6  \n1596     11.0        6  \n1597     10.2        5  \n1598     11.0        6  \n\n[1599 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(link, delimiter=';')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9882720875684128 0.9882720875684128\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(random_state=42)\n",
    "Bagging = BaggingClassifier(random_state=42)\n",
    "DecisionTree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "x = data.loc[:,:'chlorides']\n",
    "y = data['quality']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)\n",
    "\n",
    "RandomForest_fit = RandomForest.fit(x_train, y_train)\n",
    "Bagging_fit = Bagging.fit(x_train, y_train)\n",
    "DecisionTree_fit = Bagging.fit(x_train, y_train)\n",
    "\n",
    "RandomForest_fit_score = RandomForest_fit.score(x_train, y_train)\n",
    "Bagging_fit_score = Bagging_fit.score(x_train, y_train)\n",
    "DecisionTree_fit_score = DecisionTree_fit.score(x_train, y_train)\n",
    "\n",
    "print(RandomForest_fit_score, Bagging_fit_score, DecisionTree_fit_score)\n",
    "#каждый параметр высчитывает необходимые показатели, на совокупности которых можно найти более точные значения\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "cnt = [10, 50, 100]\n",
    "rng = []\n",
    "for i in range(200, 5000, 200):\n",
    "    rng.append(i)\n",
    "cnt_rng = cnt + rng\n",
    "\n",
    "result = []\n",
    "\n",
    "for c in cnt_rng:\n",
    "    clf = RandomForestClassifier(n_estimators=c, random_state=42, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    res_test = clf.score(x_test, y_test)\n",
    "    res_train = clf.score(x_train, y_train)\n",
    "    result.append({'c': c, 'res_test': res_test})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x22a6ead7ee0>]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "\n",
    "plt.plot(result_df.c, result_df.res_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier_name 0.4202626641651032\n",
      "[16:00:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrWind\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\MrWind\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrWind\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier_name 0.4208880550343965\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    {'name':'GradientBoostingClassifier_name', 'classifier': GradientBoostingClassifier(random_state=42)},\n",
    "    {'name': 'XGBClassifier_name', 'classifier': XGBClassifier(random_state=42)}\n",
    "]\n",
    "\n",
    "for clas in classifiers:\n",
    "    classifier_name = clas['name']\n",
    "    classifier = clas['classifier']\n",
    "    cross_val = cross_val_score(classifier, x, y, scoring=\"accuracy\", cv=3).mean()\n",
    "    print(classifier_name,  cross_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> {'learning_rate': 1, 'max_depth': 2, 'n_estimators': 6} 0:00:05.436282\n",
      "[19:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<class 'xgboost.sklearn.XGBClassifier'> {'learning_rate': 3, 'max_depth': 2, 'n_estimators': 10} 0:00:01.899389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrWind\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    {'name': GradientBoostingClassifier, 'parametr': [{'learning_rate': [1, 2, 3], 'n_estimators': [6, 8, 10], 'max_depth': [2, 3, 4]}]},\n",
    "    {'name': XGBClassifier, 'parametr': [{'learning_rate': [1, 2, 3], 'n_estimators': [6, 8, 10], 'max_depth': [2, 3, 4]}]}\n",
    "]\n",
    "list = []\n",
    "for c in classifiers:\n",
    "    classifier_name = c['name']\n",
    "    params = c['parametr']\n",
    "    start_time = datetime.now()\n",
    "    acc = GridSearchCV(classifier_name(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(x, y)\n",
    "    lst = pd.DataFrame(acc.cv_results_)\n",
    "    lst['classifier_name'] = classifier_name\n",
    "    list.append(lst)\n",
    "    print(classifier_name, acc.best_params_, datetime.now() - start_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                      accuracy\nLight_GBM_Classifier  0.485417\nCatBoost_Classifier   0.495833",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Light_GBM_Classifier</th>\n      <td>0.485417</td>\n    </tr>\n    <tr>\n      <th>CatBoost_Classifier</th>\n      <td>0.495833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'Light_GBM_Classifier': LGBMClassifier(random_state=42),\n",
    "    'CatBoost_Classifier': CatBoostClassifier(random_state=42, verbose=False)\n",
    "}\n",
    "\n",
    "result = {}\n",
    "for classifiers_name, classifier in classifiers.items():\n",
    "    classifier.fit(x_train, y_train)\n",
    "    result[classifiers_name] = np.mean(cross_val_score(classifier, x_test, y_test, scoring=\"accuracy\",cv=3))\n",
    "pd.DataFrame.from_dict(result, orient='index', columns=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2956/652717526.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m ]\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mclassifiers_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclassifier\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mclassifiers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m     \u001B[0mgrid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[0mfit_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "params_lightgbm = {\n",
    "    'learning_rate': [1, 2, 3],\n",
    "    'n_estimators': [6, 8, 10],\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "params_catboost = {\n",
    "    'learning_rate': [1, 2, 3],\n",
    "    'n_estimators': [6, 8, 10],\n",
    "    'max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "    ('Light_GBM_Classifier', LGBMClassifier(random_state=42), params_lightgbm),\n",
    "    ('CatBoost_Classifier', CatBoostClassifier(random_state=42, verbose=False), params_catboost)\n",
    "]\n",
    "\n",
    "for classifiers_name, classifier in classifiers:\n",
    "    grid = GridSearchCV(classifier, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    fit_model = grid.fit(x_train, y_train)\n",
    "    print(classifiers_name, fit_model.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-168f5327",
   "language": "python",
   "display_name": "PyCharm (ds-python)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}